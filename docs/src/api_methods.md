# Contents

```@contents
Pages=["api_methods.md"]
```

# Barzilai Borwein Method

```@docs
barzilai_borwein_gd
BarzilaiBorweinGD
```

# Gradient Descent with Fixed Step Size

```@docs
fixed_step_gd
FixedStepGD
```

# Lipschitz Approximation (Malitsky & Mishchenko)

```@docs
lipschitz_approximation_gd
LipschitzApproxGD
```

# Weighted Norm Damping Gradient Method (WNGrad)

```@docs
weighted_norm_damping_gd
WeightedNormDampingGD
```

# Nesterov's Accelerated Gradient Descent

```@docs
nesterov_accelerated_gd

NesterovAcceleratedGD
```

# Gradient Descent with Diminishing Step Size
```@docs
DiminishingStepGD

diminishing_step_gd
```

Below is a list of step size functions that are in the library.
The step size sequence generated by these functions, ``\lbrace \alpha_k \rbrace`` 
satisfies ``\alpha_k > 0``, ``\lim_{k \to\infty} \alpha_k = 0`` and 
``\sum_{k=0}^\infty \alpha_k = \infty``.


```@docs
OptimizationMethods.inverse_k_step_size

OptimizationMethods.inverse_log2k_step_size

OptimizationMethods.stepdown_100_step_size
```

# Gradient Descent with EBLS for Weak Wolfe Conditions
```@docs
wolfe_ebls_gd

WolfeEBLSGD
```

# Index 
```@index
```
