# Contents

```@contents
Pages=["api_methods.md"]
```

# Barzilai Borwein Method

```@docs
barzilai_borwein_gd
BarzilaiBorweinGD
```

# Gradient Descent with Fixed Step Size

```@docs
fixed_step_gd
FixedStepGD
```

# Lipschitz Approximation (Malitsky & Mishchenko)

```@docs
lipschitz_approximation_gd
LipschitzApproxGD
```

# Weighted Norm Damping Gradient Method (WNGrad)

```@docs
weighted_norm_damping_gd
WeightedNormDampingGD
```

# Nesterov's Accelerated Gradient Descent

```@docs
nesterov_accelerated_gd

NesterovAcceleratedGD
```

# Gradient Descent with Diminishing Step Size
```@docs
diminishing_step_gd

DiminishingStepGD
```

Below is a list of step size functions that are in the library.
The step size sequence generated by these functions, ``\lbrace \alpha_k \rbrace`` 
satisfies ``\alpha_k > 0``, ``\lim_{k \to\infty} \alpha_k = 0`` and 
``\sum_{k=0}^\infty \alpha_k = \infty``.


```@docs
OptimizationMethods.inverse_k_step_size

OptimizationMethods.inverse_log2k_step_size

OptimizationMethods.stepdown_100_step_size
```

# Non-sequential Armijo Line Search with Event Triggered Objective Evaluations

## First Order Methods
```@docs
nonsequential_armijo_adaptive_gd

NonsequentialArmijoAdaptiveGD

nonsequential_armijo_fixed_gd

NonsequentialArmijoFixedGD
```

## Second Order Methods
```@docs
nonsequential_armijo_mnewton_fixed_gd

NonsequentialArmijoFixedMNewtonGD
```

The methods above require several utility functions. These are listed
below.

```@docs
OptimizationMethods.update_local_lipschitz_approximation

OptimizationMethods.compute_step_size

OptimizationMethods.inner_loop!

OptimizationMethods.update_algorithm_parameters!
```

# Line search Helper Functions

## Non-sequential Armijo Line Search
```@docs
OptimizationMethods.non_sequential_armijo_condition
```

# Index 
```@index
```
