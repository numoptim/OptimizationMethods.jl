# Date: 12/19/2024
# Author: Christian Varner
# Purpose: Implement a quasi-likelihood examples
# with a linear mean and variance function that is 1 + mean + sin(2pi*mean)

"""
    QLLogisticSin{T, S} <: AbstractDefaultQL{T, S}

Implements a Quasi-likelihood objective with a logistic link function and
    `linear_plus_sin` variance funtion. If the design matrix and the
    responses are not supplied, they are randomly generated.

# Objective Function

Let ``A`` be the design matrix, and ``b`` be the responses. Each row of ``A``
    and corresponding entry in ``b`` are the predictor and observations from one
    unit. The statistical model for this objective function assums ``b``
    are between ``0`` and ``1``.

Let ``A_i`` be row ``i`` of ``A`` and ``b_i`` entry ``i`` of ``b``. Let
```math
    \\mu_i(x) = \\mathrm{logistic}(A_i^\\intercal x)
```
and
```math
    v_i(\\mu) = 1 + \\mu + \\sin(2 \\pi \\mu). 
```

Let ``n`` be the number of rows in ``A``, then the quasi-likelihood objective is
```math
    F(x) = -\\sum_{i=1}^n \\int_0^{\\mu_i(x)} \\frac{b_i - m}{v_i(m)} dm.
```

!!! warn
    ``F(x)`` does not have an easily expressible closed form, so a numerical
    integration scheme is used to evaluate the objective. The gradient
    and hessian have closed form solutions however.

# Fields

- `meta::NLPModelMeta{T, S}`, NLPModel struct for storing meta information for 
    the problem
- `counters::Counters`, NLPModel Counter struct that provides evaluations 
    tracking.
- `design::Matrix{T}`, covariate matrix for the problem/experiment (``A``).
- `response::Vector{T}`, observations for the problem/experiment (``b``).
- `mean::Function`, component-wise function of the linear predictor ``Ax`` 
    to predict expected value of the response.
- `mean_first_derivative::Function`, function for the first derivative of the 
    mean function.
- `mean_second_derivative::Function`, function for the second derivative of the
    mean funciton.
- `variance::Function`, variance function that estimates the variance of each
    response.
- `variance_first_derivative::Function`, function that returns the first 
    derivative of the variance function.
- `weighted_residual::Function`, computes the weighted residual of the model. 

# Constructors

## Inner Constructors

    QLLogisticSin{T, S}(meta::NLPModelMeta{T, S}, counters::Counters,
        design::Matrix{T}, response::Vector{T})
    
Initializes the data structure for a quasi-likelihood estimation problem with 
    a [logistic link function](@ref OptimizationMethods.logistic) and 
    a [linear plus sine variance function](@ref OptimizationMethods.linear_plus_sin).

## Outer Constructors

    QLLogisticSin(::Type{T}; nobs::Int64 = 1000,
        nvar::Int64 = 50) where {T}

Construct a quasi-likelihood estimation problem with 
    a [logistic link function](@ref OptimizationMethods.logistic); 
    a [linear plus sine variance function](@ref OptimizationMethods.linear_plus_sin);
    and a randomly generated `design` matrix and `response` vector that is consistent 
    with the quasi-likelihood model. 
    The `design` matrix has a column of all ones and the rest generated from a 
    normal distribution with its entries divided by `sqrt(nvar - 1)`. 
    The `response` vector has entries generated by 
    `mean.(design * x) + variance.(mean.(design * x)) .^ (.5) * ϵ`, where `ϵ` is a noise
    vector generated from the Arcsine distribution with default parameters.
 
    QLLogisticSin(design::Matrix{T}, response::Vector{T}; 
        x0::Vector{T} = zeros(T, size(design)[2])) where {T}

Constructs a quasi-likelihood estimation problem with 
    a [logistic link function](@ref OptimizationMethods.logistic); 
    a [linear plus sine variance function](@ref OptimizationMethods.linear_plus_sin);
    and user-supplied `design` matrix and `response` vector.
"""
mutable struct QLLogisticSin{T, S} <: AbstractDefaultQL{T, S}
    meta::NLPModelMeta{T, S}
    counters::Counters
    design::Matrix{T}
    response::Vector{T}
    mean::Function
    mean_first_derivative::Function
    mean_second_derivative::Function
    variance::Function
    variance_first_derivative::Function
    weighted_residual::Function

    QLLogisticSin{T, S}(meta::NLPModelMeta{T, S}, counters::Counters, 
        design::Matrix{T}, response::Vector{T}) where {T, S} = 
    begin
        weighted_residual(μ, y) = (y - μ)/OptimizationMethods.linear_plus_sin(μ) 
        new(meta, counters, design, response, 
            OptimizationMethods.logistic,           # force the correct mean function
            OptimizationMethods.dlogistic,          # force the correct derivative function
            OptimizationMethods.ddlogistic,         # force the correct derivative function
            OptimizationMethods.linear_plus_sin,    # force the correct variance function
            OptimizationMethods.dlinear_plus_sin,   # force the correct derivative function
            weighted_residual                       # residual function
        )
    end
end
function QLLogisticSin(
    ::Type{T};
    nobs::Int64 = 1000,
    nvar::Int64 = 50
) where {T}

    @assert nobs > 0 "Number of observations ($(nobs)) must be positive."
    
    @assert nvar > 0 "Number of variables ($(nvar)) must be positive."

    # initialize the meta data and counters
    meta = NLPModelMeta(
        nvar,
        name = "Quasi-likelihood with logistic link function and sine variance",
        x0 = zeros(T, nvar)
    )
    counters = Counters()

    # simulate the design matrix
    design = hcat(ones(T, nobs), randn(T, nobs, nvar-1) ./ T(sqrt(nvar - 1)))

    # get reponses
    β_true_mean = randn(T, nvar)
    β_true = β_true_mean + randn(T, nvar)
    η = design * β_true
    μ_obs = OptimizationMethods.logistic.(η)
    ϵ = T.((rand(Distributions.Arcsine()) .- .5)./(1/8)) # standardize

    # generate responses
    response = μ_obs + T.(OptimizationMethods.linear_plus_sin.(μ_obs) .^ (.5)) * ϵ

    return QLLogisticSin{T, Vector{T}}(
        meta,
        counters,
        design,
        response
    )
end
function QLLogisticSin(
    design::Matrix{T},
    response::Vector{T};
    x0::Vector{T} = zeros(T, size(design)[2])
) where {T}

    @assert size(design, 1) == size(response, 1) "Number rows in design matrix"*
    " must be equal to the number of observations."

    @assert size(design, 2) == size(x0, 1) "Number of columns in design matrix"*
    " must be equal to parameter dimension."
    
    # initialize meta
    meta = NLPModelMeta(
            size(design, 2),
            name = "Quasi-likelihood with logistic link function and sine variance",
            x0 = x0
           )

    # initialize counters
    counters = Counters()

    # return the struct
    return QLLogisticSin{T, Vector{T}}(
        meta,
        counters,
        design,
        response,
    )
end

# precompute struct
"""
    PrecomputeQLLogisticSin{T} <: AbstractDefaultQLPrecompute{T}

Structure that holds precomputed values for the quasi-likelihood problem.
    These values are precomputed to save on time, and they remain unchanged
    throughout the algorithm.

# Fields

- `obs_obs_t`, 3d array where `obs_obs_t[i, :, :]` contains the outer produce
    between the ith covariate vector and itself.

# Constructor

    PrecomputeQLLogisticSin(progData::QLLogisticSin{T, S}) where {T, S}

Initializes the field values for the precompute data structure and returns 
    a `struct`.
"""
struct PrecomputeQLLogisticSin{T} <: AbstractDefaultQLPrecompute{T}
    obs_obs_t::Array{T, 3}
end
function PrecomputeQLLogisticSin(progData::QLLogisticSin{T, S}) where {T, S}

    # get the size of the matrix
    nobs, nvar = size(progData.design)

    # create the space
    obs_obs_t = zeros(T, nobs, nvar, nvar)
    
    for i in 1:nobs
        obs_obs_t[i, :, :] .= view(progData.design, i, :) *
            view(progData.design, i, :)'
    end

    return PrecomputeQLLogisticSin{T}(obs_obs_t)
end

# allocate struct
"""
    AllocateQLLogisticSin{T} <: AbstractDefaultQLAllocate{T}

Mutable struct that contains buffer arrays for various computations used for
    this objective function and for optimization algorithms.

# Fields

- `linear_effect::Vector{T}`, buffer array for `progData.response * x`.   
- `μ::Vector{T}`, buffer array for response prediction.
- `∇μ_η::Vector{T}`, buffer array for first derivatives for the mean function
    evaluated at each point in `linear_effect`.
- `∇∇μ_η::Vector{T}`, buffer arry for second derivatives for the mean function
    evaluated at each point in `linear_effect`.
- `variance::Vector{T}`, buffer array for the variance function evaluated at
    each point `μ`
- `∇variance::Vector{T}`, buffer array for the first derivatives for the 
    variance function evaluated at each point in `μ`
- `weighted_residual::Vector{T}`, buffer array for the weighted residuals.
- `grad::Vector{T}`, buffer array for the gradient vector.
- `hess::Matrix{T}`, buffer matrix for the hessian.

# Constructors

    AllocateQLLogisticSin(progData::QLLogisticSin{T,S}) where {T,S}

Allocates memory for each of the field values and returns the struct.
"""
struct AllocateQLLogisticSin{T} <: AbstractDefaultQLAllocate{T}
    linear_effect::Vector{T}   
    μ::Vector{T}
    ∇μ_η::Vector{T}
    ∇∇μ_η::Vector{T}
    variance::Vector{T}
    ∇variance::Vector{T}
    weighted_residual::Vector{T}
    grad::Vector{T}
    hess::Matrix{T}
end
function AllocateQLLogisticSin(progData::QLLogisticSin{T, S}) where {T, S}

    # get dimensions
    nobs = size(progData.design, 1)
    nvar = size(progData.design, 2)

    # initialize memory
    linear_effect = zeros(T, nobs)
    μ = zeros(T, nobs)
    ∇μ_η = zeros(T, nobs)
    ∇∇μ_η = zeros(T, nobs)
    variance = zeros(T, nobs)
    ∇variance = zeros(T, nobs)
    weighted_residual = zeros(T, nobs)
    grad = zeros(T, nvar)
    hess = zeros(T, nvar, nvar)

    return AllocateQLLogisticSin(
        linear_effect,           # buffer for linear effect
        μ, ∇μ_η, ∇∇μ_η,          # mean, first, and second derivative link
        variance, ∇variance,     # variance and first derivative 
        weighted_residual,       # buffer for weighted residual
        grad,                    # buffer for gradient
        hess                     # buffer for hessian
    )
end

"""
    initialize(progData::QLLogisticSin{T,S}) where {T,S}

Creates a `PrecomputeQLLogisticSin` and `AllocateQLLogisticSin` struct, returning
    them in that order.
"""
function initialize(progData::QLLogisticSin{T, S}) where {T, S}
    precomp = PrecomputeQLLogisticSin(progData)
    store = AllocateQLLogisticSin(progData)

    return precomp, store
end